model_name: "WALL-E_GPT-1"
dataset_path: "~/datasets/wikipedia_WALL-E_tokenized.hdf5"
model_path: "~/model_weights/"
checkpoint_path: "~/model_weights/WALL-E_GPT-1.pt"
chunk_size: 512
epochs: 100
num_layers: 12
num_heads: 12
d_model: 768
learning_rate: 2.5e-4
batch_size: 96
warmup_epochs: 5
num_workers: 8
checkpoint_interval: 1
save_to_s3: True
s3_path: "s3://zima-data/model_weights/"
